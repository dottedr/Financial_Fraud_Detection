{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas, numpy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>C786484425</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C776919290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1529008245</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1881841831</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>C1162922333</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1365125890</td>\n",
       "      <td>68488.84</td>\n",
       "      <td>6379898.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1685995037</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C2080388513</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>C1280323807</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C873221189</td>\n",
       "      <td>6510099.11</td>\n",
       "      <td>7360101.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362620 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step      type      amount     nameOrig  oldbalanceOrg  \\\n",
       "0           1   PAYMENT     9839.64  C1231006815      170136.00   \n",
       "1           1   PAYMENT     1864.28  C1666544295       21249.00   \n",
       "2           1  TRANSFER      181.00  C1305486145         181.00   \n",
       "3           1  CASH_OUT      181.00   C840083671         181.00   \n",
       "4           1   PAYMENT    11668.14  C2048537720       41554.00   \n",
       "...       ...       ...         ...          ...            ...   \n",
       "6362615   743  CASH_OUT   339682.13   C786484425      339682.13   \n",
       "6362616   743  TRANSFER  6311409.28  C1529008245     6311409.28   \n",
       "6362617   743  CASH_OUT  6311409.28  C1162922333     6311409.28   \n",
       "6362618   743  TRANSFER   850002.52  C1685995037      850002.52   \n",
       "6362619   743  CASH_OUT   850002.52  C1280323807      850002.52   \n",
       "\n",
       "         newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  \\\n",
       "0             160296.36  M1979787155            0.00            0.00        0   \n",
       "1              19384.72  M2044282225            0.00            0.00        0   \n",
       "2                  0.00   C553264065            0.00            0.00        1   \n",
       "3                  0.00    C38997010        21182.00            0.00        1   \n",
       "4              29885.86  M1230701703            0.00            0.00        0   \n",
       "...                 ...          ...             ...             ...      ...   \n",
       "6362615            0.00   C776919290            0.00       339682.13        1   \n",
       "6362616            0.00  C1881841831            0.00            0.00        1   \n",
       "6362617            0.00  C1365125890        68488.84      6379898.11        1   \n",
       "6362618            0.00  C2080388513            0.00            0.00        1   \n",
       "6362619            0.00   C873221189      6510099.11      7360101.63        1   \n",
       "\n",
       "         isFlaggedFraud  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "6362615               0  \n",
       "6362616               0  \n",
       "6362617               0  \n",
       "6362618               0  \n",
       "6362619               0  \n",
       "\n",
       "[6362620 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1=pandas.read_csv(\"PS_20174392719_1491204439457_log.csv\", na_values=['NA', '?'])\n",
    "pandas.set_option('display.max_columns', None)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DF: 5089921\n",
      "Validation DF: 1272699\n"
     ]
    }
   ],
   "source": [
    "df1=df1.reindex(numpy.random.permutation(df1.index))\n",
    "mask=numpy.random.rand(len(df1))<0.8\n",
    "trainDF=pandas.DataFrame(df1[mask])\n",
    "validationDF=pandas.DataFrame(df1[~mask])\n",
    "\n",
    "print(f\"Training DF: {len(trainDF)}\")\n",
    "print(f\"Validation DF: {len(validationDF)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold#1, Training Size: 5090096,  Validation Size: 1272699\n",
      "Fold#2, Training Size: 5090096,  Validation Size: 1272699\n",
      "Fold#3, Training Size: 5090096,  Validation Size: 1272699\n",
      "Fold#4, Training Size: 5090096,  Validation Size: 1272699\n",
      "Fold#5, Training Size: 5090096,  Validation Size: 1272699\n"
     ]
    }
   ],
   "source": [
    "df2=pandas.read_csv(\"PS_20174392719_1491204439457_log.csv\", na_values=['NA', '?'])\n",
    "df2=df2.reindex(numpy.random.permutation(df2.index))\n",
    "kf =KFold(5)\n",
    "\n",
    "fold = 1\n",
    "for train_index, validate_index in kf.split(df2):\n",
    "    trainDF=pandas.DataFrame(df2.iloc[train_index, :])\n",
    "    validateDF=pandas.DataFrame(df2.iloc[validate_index])\n",
    "    print(f\"Fold#{fold}, Training Size: {len(trainDF)},  Validation Size: {len(validationDF)}\")\n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced approach for perceptron training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold#1, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.34753478905145413\n",
      "Fold#2, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.16976152175198087\n",
      "Fold#3, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.344340107745453\n",
      "Fold#4, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.36372532489801923\n",
      "Fold#5, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.3714948931469615\n",
      "Fold#6, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.2615667628686794\n",
      "Fold#7, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.27281025303641837\n",
      "Fold#8, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.24343035892633336\n",
      "Fold#9, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.2602698562368943\n",
      "Fold#10, Training Size: 5726358,  Validation Size: 636262\n",
      "Accuracy: 1.00\n",
      "precision score: 0.2712254234806884\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset as dataframe\n",
    "df3=pandas.read_csv(\"PS_20174392719_1491204439457_log.csv\", na_values=['NA', '?'])\n",
    "\n",
    "#shuffling the data\n",
    "df3=df3.reindex(numpy.random.permutation(df3.index))\n",
    "\n",
    "#make ints from string column \"type\" and remove old one\n",
    "enc=LabelEncoder()\n",
    "column_name= \"type\"\n",
    "space=1\n",
    "enc.fit(df3[column_name])\n",
    "enc_type = enc.transform(df3[column_name])\n",
    "df3.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "df3.pop(\"type\")\n",
    "\n",
    "column_name= \"nameOrig\"\n",
    "space=3\n",
    "enc.fit(df3[column_name])\n",
    "enc_type = enc.transform(df3[column_name])\n",
    "df3.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "df3.pop(\"nameOrig\")\n",
    "\n",
    "column_name= \"nameDest\"\n",
    "space=6\n",
    "enc.fit(df3[column_name])\n",
    "enc_type = enc.transform(df3[column_name])\n",
    "df3.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "df3.pop(\"nameDest\")\n",
    "# end of encoding the string columns\n",
    "\n",
    "result = []\n",
    "for x in df3.columns:\n",
    "    if x != 'isFraud':\n",
    "        result.append(x)\n",
    "\n",
    "# x and y data\n",
    "X=df3[result].values\n",
    "y=df3['isFraud'].values\n",
    "\n",
    "#Perceptron creation\n",
    "ppn=Perceptron(max_iter=70, tol=0.0001, eta0=1)\n",
    "\n",
    "#k-fold splitting to 10\n",
    "kf =KFold(10)\n",
    "\n",
    "fold = 1\n",
    "for train_index, validate_index in kf.split(X, y):\n",
    "    ppn.fit(X[train_index], y[train_index])\n",
    "    y_test=y[validate_index]\n",
    "    y_pred=ppn.predict(X[validate_index])\n",
    "    \n",
    "    # print the fold nuumber and sizes\n",
    "    print(f\"Fold#{fold}, Training Size: {len(X[train_index])},  Validation Size: {len(X[validate_index])}\")\n",
    "    \n",
    "    #print accuracy \n",
    "    print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #precision check\n",
    "    precision = metrics.average_precision_score(y_test, y_pred)\n",
    "    print(\"precision score: {}\".format(precision))\n",
    "    \n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6354407\n",
      "1       8213\n",
      "Name: isFraud, dtype: int64\n",
      "0    0.998709\n",
      "1    0.001291\n",
      "Name: isFraud, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#show the balance of the dataset in both real numbers and percentage\n",
    "print(df3[\"isFraud\"].value_counts())\n",
    "print(df3[\"isFraud\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, balancing out the dataset, by creating a smaller one and checking the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold#1, Training Size: 12800,  Validation Size: 3200\n",
      "Accuracy: 0.91\n",
      "Precision: 0.87\n",
      "Recall: 0.96\n",
      "Fold#2, Training Size: 12800,  Validation Size: 3200\n",
      "Accuracy: 0.86\n",
      "Precision: 0.79\n",
      "Recall: 0.98\n",
      "Fold#3, Training Size: 12800,  Validation Size: 3200\n",
      "Accuracy: 0.92\n",
      "Precision: 0.88\n",
      "Recall: 0.95\n",
      "Fold#4, Training Size: 12800,  Validation Size: 3200\n",
      "Accuracy: 0.93\n",
      "Precision: 0.89\n",
      "Recall: 0.96\n",
      "Fold#5, Training Size: 12800,  Validation Size: 3200\n",
      "Accuracy: 0.93\n",
      "Precision: 0.88\n",
      "Recall: 0.96\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "df4=pandas.read_csv(\"PS_20174392719_1491204439457_log.csv\", na_values=['NA', '?'])\n",
    "\n",
    "#shuffle the original dataset\n",
    "df4=df4.reindex(numpy.random.permutation(df4.index))\n",
    "\n",
    "#create smaller balanced dataset for training perceptron\n",
    "df_positive=df4.loc[df4[\"isFraud\"]==1].head(8000)\n",
    "df_negative=df4.loc[df4[\"isFraud\"]==0].head(8000)\n",
    "dfSmall= pandas.concat([df_positive, df_negative])\n",
    "dfSmall=dfSmall.reindex(numpy.random.permutation(dfSmall.index))\n",
    "\n",
    "\n",
    "#make ints from string columns and remove old one\n",
    "enc=LabelEncoder()\n",
    "column_name= \"type\"\n",
    "space=1\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"type\")\n",
    "\n",
    "column_name= \"nameOrig\"\n",
    "space=3\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"nameOrig\")\n",
    "\n",
    "column_name= \"nameDest\"\n",
    "space=6\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"nameDest\")\n",
    "\n",
    "\n",
    "result = []\n",
    "for x in dfSmall.columns:\n",
    "    if x != 'isFraud':\n",
    "        result.append(x)\n",
    "\n",
    "# x and y data\n",
    "X=dfSmall[result].values\n",
    "y=dfSmall['isFraud'].values\n",
    "\n",
    "#Perceptron creation\n",
    "ppn=Perceptron(max_iter=50, tol=0.001, eta0=1)\n",
    "\n",
    "#k-fold splitting to 5(for now, might be good with 10 as well)\n",
    "kf =KFold(5)\n",
    "\n",
    "fold = 1\n",
    "for train_index, validate_index in kf.split(X, y):\n",
    "    ppn.fit(X[train_index], y[train_index])\n",
    "    y_test=y[validate_index]\n",
    "    y_pred=ppn.predict(X[validate_index])\n",
    "    \n",
    "    #print fold number and sizes\n",
    "    print(f\"Fold#{fold}, Training Size: {len(X[train_index])},  Validation Size: {len(X[validate_index])}\")\n",
    "    #accuracy printing\n",
    "    print(\"Accuracy: %.2f\" % accuracy_score(y_test, y_pred))\n",
    "    #precision check\n",
    "    precision = metrics.average_precision_score(y_test, y_pred)\n",
    "    print(\"Precision: %.2f\" %precision)\n",
    "    #recall\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    print(\"Recall: %.2f\" %recall)\n",
    "    fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The code above creates the new balanced dataset and dataframe to be 50/50 in fraudulent transactions\n",
    "#we use perceptron, and a 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest tree  below, to show accuracy, precision, confusion matrix and f1 next snippet needs to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "#load dataset\n",
    "df5=pandas.read_csv(\"PS_20174392719_1491204439457_log.csv\", na_values=['NA', '?'])\n",
    "\n",
    "#create smaller balanced dataset for training perceptron\n",
    "df_positive=df5.loc[df5[\"isFraud\"]==1].head(8000)\n",
    "df_negative=df5.loc[df5[\"isFraud\"]==0].head(8000)\n",
    "dfSmall= pandas.concat([df_positive, df_negative])\n",
    "dfSmall=dfSmall.reindex(numpy.random.permutation(dfSmall.index))\n",
    "\n",
    "#make ints from string columns and remove old one\n",
    "enc=LabelEncoder()\n",
    "column_name= \"type\"\n",
    "space=1\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"type\")\n",
    "\n",
    "column_name= \"nameOrig\"\n",
    "space=3\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"nameOrig\")\n",
    "\n",
    "column_name= \"nameDest\"\n",
    "space=6\n",
    "enc.fit(dfSmall[column_name])\n",
    "enc_type = enc.transform(dfSmall[column_name])\n",
    "dfSmall.insert(space,\"encoded_\" + column_name,enc_type)\n",
    "dfSmall.pop(\"nameDest\")\n",
    "\n",
    "result = []\n",
    "for x in dfSmall.columns:\n",
    "    if x != 'isFraud':\n",
    "        result.append(x)\n",
    "        \n",
    "X=dfSmall[result].values\n",
    "y=dfSmall['isFraud'].values\n",
    "\n",
    "#split dataset to training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# create a classifier\n",
    "classifier=RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998\n",
      "Precision: 0.998\n",
      "Conufion Matrix: \n",
      " [[2392    0]\n",
      " [  12 2396]]\n",
      "f1 score: 0.998 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.3f\" %accuracy)\n",
    "\n",
    "# print precission\n",
    "precision = metrics.average_precision_score(y_test, y_pred)\n",
    "print(\"Precision: %.3f\" %precision)\n",
    "\n",
    "# print confusion matrix\n",
    "cmatrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(\"Conufion Matrix: \\n\",cmatrix)\n",
    "\n",
    "# print f1 score for binary targets\n",
    "f1 = metrics.f1_score(y_test, y_pred)\n",
    "print(\"f1 score: %.3f \\n\" %f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
